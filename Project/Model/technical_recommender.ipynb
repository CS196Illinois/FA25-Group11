{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Course Recommender\n",
    "\n",
    "## Core Steps:\n",
    "1. Load major requirements and extract technical courses/electives\n",
    "2. Filter courses based on prerequisites (courses user can take)\n",
    "3. Filter courses based on postrequisites (courses that lead somewhere)\n",
    "4. Build text corpus from course titles and descriptions\n",
    "5. Apply TF-IDF vectorization (1-2 grams) + cosine similarity to user interests\n",
    "6. Diversify with MMR\n",
    "7. Return top-N technical course recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3309ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fuzzywuzzy in /Users/melinanguyen/Library/Python/3.9/lib/python/site-packages (0.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3f2376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Optional\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Add backend to path for importing services\n",
    "sys.path.append(str(Path('../backend').resolve()))\n",
    "\n",
    "# Import backend services for robust prerequisite checking and data loading\n",
    "from app.services.prereq_checker import (\n",
    "    normalize_course_code,\n",
    "    can_take_course,\n",
    "    check_prerequisites_met\n",
    ")\n",
    "from app.services.year_detector import detect_student_year\n",
    "\n",
    "# Add pdf_to_dars to path\n",
    "sys.path.append(str(Path('../pdf_to_dars').resolve()))\n",
    "\n",
    "# Import DARS parser (optional - only if available)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b982842",
   "metadata": {},
   "source": [
    "## 1. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1140e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded prerequisite graph with 7968 courses\n",
      "Loaded postrequisite graph with 1376 courses\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "MAJORS_FILE = \"../data_scraping/output/processed/majors_structured.json\"\n",
    "PREREQ_FILE = \"../data_scraping/output/processed/prerequisite_graph.json\"\n",
    "POSTREQ_FILE = \"../data_scraping/output/processed/postrequisite_graph.json\"\n",
    "\n",
    "def load_json(filepath: str) -> dict:\n",
    "    \"\"\"Load JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_major_requirements(filepath: str, major_name: str) -> Dict:\n",
    "    \"\"\"Load requirements for a specific major.\"\"\"\n",
    "    data = load_json(filepath)\n",
    "    if major_name not in data:\n",
    "        raise ValueError(f\"Major '{major_name}' not found in data\")\n",
    "    return data[major_name]\n",
    "\n",
    "# Load prerequisite and postrequisite graphs\n",
    "prereq_graph = load_json(PREREQ_FILE)\n",
    "postreq_graph = load_json(POSTREQ_FILE)\n",
    "\n",
    "print(f\"Loaded prerequisite graph with {len(prereq_graph)} courses\")\n",
    "print(f\"Loaded postrequisite graph with {len(postreq_graph)} courses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf7e24",
   "metadata": {},
   "source": [
    "## 2. Extract Technical Courses from Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5727126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_technical_courses(major_data: Dict) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Extract technical courses from major requirements.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    required_courses = []\n",
    "    elective_courses = []\n",
    "    area_courses = []\n",
    "\n",
    "    for group in major_data.get('requirement_groups', []):\n",
    "        group_name = group.get('group_name', '').lower()\n",
    "\n",
    "        # Check if this is a technical group\n",
    "        is_technical = any(keyword in group_name for keyword in [\n",
    "            'technical', 'elective', 'cs ', 'computer science',\n",
    "            'programming', 'advanced', 'areas', 'specialization',\n",
    "            'core', 'major', 'concentration'\n",
    "        ])\n",
    "\n",
    "        is_elective = any(keyword in group_name for keyword in [\n",
    "            'elective', 'choose', 'select', 'option'\n",
    "        ])\n",
    "\n",
    "        is_area = 'area' in group_name or 'specialization' in group_name\n",
    "\n",
    "        # Extract courses from this group\n",
    "        for course in group.get('courses', []):\n",
    "            if isinstance(course, dict) and 'code' in course:\n",
    "                course_code = course['code']\n",
    "\n",
    "                if is_area:\n",
    "                    area_courses.append(course_code)\n",
    "                elif is_elective or not course.get('required', True):\n",
    "                    elective_courses.append(course_code)\n",
    "                elif is_technical or course.get('required', False):\n",
    "                    required_courses.append(course_code)\n",
    "\n",
    "        # Also check course_codes list\n",
    "        for course_code in group.get('course_codes', []):\n",
    "            if is_area:\n",
    "                area_courses.append(course_code)\n",
    "            elif is_elective:\n",
    "                elective_courses.append(course_code)\n",
    "            elif is_technical:\n",
    "                required_courses.append(course_code)\n",
    "\n",
    "    return {\n",
    "        'required': list(set(required_courses)),\n",
    "        'electives': list(set(elective_courses)),\n",
    "        'areas': list(set(area_courses))\n",
    "    }\n",
    "\n",
    "# This will be set when you run the profile cell below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda693d",
   "metadata": {},
   "source": [
    "<cell_type>markdown</cell_type>## 3. Prerequisite Filtering with Backend Integration\n",
    "\n",
    "Now using robust prerequisite checking from backend services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59184fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "def get_eligible_courses_improved(\n",
    "    candidate_courses: List[str],\n",
    "    courses_completed: List[str],\n",
    "    courses_in_progress: List[str],\n",
    "    prereq_graph: Dict[str, List[str]]\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Filter courses based on prerequisites using backend prereq_checker.\n",
    "    \"\"\"\n",
    "    eligible = []\n",
    "    completed_or_in_progress = set(courses_completed + courses_in_progress)\n",
    "\n",
    "    for course in candidate_courses:\n",
    "        # Build course data dict with prerequisites\n",
    "        course_data = {\n",
    "            'prerequisites': prereq_graph.get(course, [])\n",
    "        }\n",
    "\n",
    "        # Use backend's robust prerequisite checking\n",
    "        can_take, missing = can_take_course(\n",
    "            course,\n",
    "            completed_or_in_progress,\n",
    "            course_data\n",
    "        )\n",
    "\n",
    "        if can_take:\n",
    "            eligible.append(course)\n",
    "\n",
    "    return eligible\n",
    "\n",
    "def filter_by_postrequisites(\n",
    "    courses: List[str],\n",
    "    postreq_graph: Dict[str, List[str]],\n",
    "    min_postreqs: int = 0\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Filter courses that have postrequisites (lead to other courses).\n",
    "    Useful for finding courses that open up more options.\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    for course in courses:\n",
    "        postreqs = postreq_graph.get(course, [])\n",
    "        if len(postreqs) >= min_postreqs:\n",
    "            filtered.append(course)\n",
    "    return filtered\n",
    "\n",
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6c476",
   "metadata": {},
   "source": [
    "## 4. Load Real Course Data from CSV\n",
    "\n",
    "Instead of creating synthetic features, we'll use actual course names and descriptions from the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b0b63461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14382 courses from catalog\n"
     ]
    }
   ],
   "source": [
    "# Load course data from CSV (same as gened_recommender)\n",
    "COURSES_FILE = \"../data_scraping/raw_data/all_courses.csv\"\n",
    "\n",
    "def load_course_data(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load course data from CSV file.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Normalize course_id: turn non-breaking space into a normal space\n",
    "    df['course_code'] = (\n",
    "        df['course_id']\n",
    "        .astype(str)\n",
    "        .str.replace('\\xa0', ' ', regex=False)   # important!\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    # Combine name and description for richer text features\n",
    "    df['text'] = df['name'].fillna('') + ' ' + df['description'].fillna('')\n",
    "\n",
    "    # Extract subject and number from the CLEANED code, not course_id\n",
    "    df[['subject', 'number']] = df['course_code'].str.extract(r'^([A-Z]+)\\s+(\\d+)$')\n",
    "\n",
    "    # Infer level from the numeric part (or you could just map df['course_level'])\n",
    "    def get_level(num_str):\n",
    "        try:\n",
    "            num = int(num_str)\n",
    "            if num >= 400:\n",
    "                return 'advanced'\n",
    "            elif num >= 200:\n",
    "                return 'intermediate'\n",
    "            else:\n",
    "                return 'introductory'\n",
    "        except Exception:\n",
    "            return 'unknown'\n",
    "\n",
    "    df['level'] = df['number'].apply(get_level)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load all courses\n",
    "all_courses_df = load_course_data(COURSES_FILE)\n",
    "\n",
    "print(f\"Loaded {len(all_courses_df)} courses from catalog\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a112178",
   "metadata": {},
   "source": [
    "## 5. TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a5736f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF matrix shape: (43, 952)\n",
      "Number of courses: 43\n",
      "Number of features (unique terms): 952\n"
     ]
    }
   ],
   "source": [
    "def build_text_corpus(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build text corpus from course data.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df[\"name\"].fillna(\"\").astype(str) + \" \" +\n",
    "        df[\"description\"].fillna(\"\").astype(str) + \" \" +\n",
    "        df[\"subject\"].fillna(\"\").astype(str) + \" \" +\n",
    "        df[\"level\"].fillna(\"\").astype(str)\n",
    "    )\n",
    "\n",
    "def fit_vectorizer(corpus: pd.Series) -> TfidfVectorizer:\n",
    "    \"\"\"Fit TF-IDF vectorizer on course corpus.\"\"\"\n",
    "    vec = TfidfVectorizer(\n",
    "        max_df=0.7,           # Ignore terms in >70% of documents\n",
    "        min_df=2,             # Include terms in at least 2 documents (filters noise)\n",
    "        ngram_range=(1, 2),   # Use unigrams and bigrams\n",
    "        stop_words='english'  # Remove English stop words\n",
    "    )\n",
    "    vec.fit(corpus)\n",
    "    return vec\n",
    "\n",
    "# Build corpus and fit vectorizer\n",
    "corpus = build_text_corpus(courses_df)\n",
    "vectorizer = fit_vectorizer(corpus)\n",
    "X_tfidf = vectorizer.transform(corpus)\n",
    "\n",
    "print(f\"\\nTF-IDF matrix shape: {X_tfidf.shape}\")\n",
    "print(f\"Number of courses: {X_tfidf.shape[0]}\")\n",
    "print(f\"Number of features (unique terms): {X_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd01d81a",
   "metadata": {},
   "source": [
    "<cell_type>markdown</cell_type>## 6. Hybrid Recommender: TF-IDF + Rule-Based Boosting\n",
    "\n",
    "Combines interest-based matching (TF-IDF) with curriculum rules (boosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e372d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_level(course_code: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract course level from code \n",
    "    \"\"\"\n",
    "    if not course_code or not isinstance(course_code, str):\n",
    "        return 5  # Default to high if can't parse\n",
    "\n",
    "    import re\n",
    "    match = re.match(r'[A-Z]{2,4}\\s*(\\d)(\\d{2})', course_code.upper())\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 5  # Default to high if can't parse\n",
    "\n",
    "\n",
    "def calculate_rule_based_boost(\n",
    "    course_row: pd.Series,\n",
    "    student_year: str,\n",
    "    prefer_foundational: bool = False,\n",
    "    prefer_advanced: bool = False\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate rule-based boost multiplier for a course.\n",
    "\n",
    "    Returns a multiplier (e.g., 1.0 = no change, 1.3 = +30%, 0.8 = -20%)\n",
    "\n",
    "    Boosts applied:\n",
    "    - Foundational courses (high postreq count): +20%\n",
    "    - Sequence-aligned courses: +15%\n",
    "    - Level-appropriate courses: +10%\n",
    "\n",
    "    Penalties applied:\n",
    "    - Too advanced for student year: -30%\n",
    "    - Very low level for advanced students: -20%\n",
    "    \"\"\"\n",
    "    boost = 1.0\n",
    "\n",
    "    # 1. Foundational boost (courses that unlock many others)\n",
    "    if prefer_foundational and course_row.get('postreq_count', 0) > 5:\n",
    "        boost *= 1.2  # +20%\n",
    "\n",
    "    # 2. Advanced course preference\n",
    "    if prefer_advanced and course_row.get('level') == 'advanced':\n",
    "        boost *= 1.3  # +30%\n",
    "\n",
    "    # 3. Level appropriateness based on student year\n",
    "    course_level = get_course_level(course_row['code'])\n",
    "    year_to_level = {\n",
    "        'freshman': 1,\n",
    "        'sophomore': 2,\n",
    "        'junior': 3,\n",
    "        'senior': 4\n",
    "    }\n",
    "    expected_level = year_to_level.get(student_year, 2)\n",
    "\n",
    "    # Boost courses at or slightly above student level\n",
    "    if course_level == expected_level or course_level == expected_level + 1:\n",
    "        boost *= 1.1  # +10%\n",
    "\n",
    "    # Penalize courses too advanced\n",
    "    elif course_level > expected_level + 1:\n",
    "        boost *= 0.7  # -30%\n",
    "\n",
    "    # Penalize very basic courses for advanced students\n",
    "    elif student_year in ['junior', 'senior'] and course_level <= 1:\n",
    "        boost *= 0.8  # -20%\n",
    "\n",
    "    return boost\n",
    "\n",
    "\n",
    "def fix_typo(text: str, valid_terms: Set[str]) -> str:\n",
    "    \"\"\"Fix typos in user input using fuzzy matching.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    fixed = []\n",
    "    for word in text.lower().split():\n",
    "        word = word.strip()\n",
    "        if word in valid_terms:\n",
    "            fixed.append(word)\n",
    "        elif valid_terms:  # Only do fuzzy match if we have valid terms\n",
    "            match, score = process.extractOne(word, list(valid_terms))\n",
    "            fixed.append(match if score > 70 else word)\n",
    "        else:\n",
    "            fixed.append(word)\n",
    "    return ' '.join(fixed)\n",
    "\n",
    "\n",
    "def mmr_diversify(\n",
    "    scores: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    topk: int,\n",
    "    lambda_param: float = 0.7\n",
    ") -> List[int]:\n",
    "    \"\"\"Maximal Marginal Relevance for diversity.\"\"\"\n",
    "    selected = []\n",
    "    candidates = np.arange(len(scores))\n",
    "\n",
    "    # Select highest scoring course first\n",
    "    first = np.argmax(scores)\n",
    "    selected.append(first)\n",
    "    candidates = np.delete(candidates, np.where(candidates == first))\n",
    "\n",
    "    while len(selected) < topk and len(candidates) > 0:\n",
    "        mmr_scores = []\n",
    "        for c in candidates:\n",
    "            relevance = scores[c]\n",
    "\n",
    "            # Calculate similarity to already selected courses\n",
    "            if len(selected) > 0:\n",
    "                sims_to_selected = cosine_similarity(\n",
    "                    X[c:c+1], X[selected]\n",
    "                ).flatten()\n",
    "                max_sim = np.max(sims_to_selected)\n",
    "            else:\n",
    "                max_sim = 0\n",
    "\n",
    "            # MMR score: balance relevance and diversity\n",
    "            mmr = lambda_param * relevance - (1 - lambda_param) * max_sim\n",
    "            mmr_scores.append(mmr)\n",
    "\n",
    "        # Select best MMR score\n",
    "        best_idx = np.argmax(mmr_scores)\n",
    "        best_candidate = candidates[best_idx]\n",
    "        selected.append(best_candidate)\n",
    "        candidates = np.delete(candidates, best_idx)\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "def recommend_technical_courses_hybrid(\n",
    "    profile: Dict,\n",
    "    major_name: str,\n",
    "    df: pd.DataFrame,\n",
    "    X_tfidf: np.ndarray,\n",
    "    vectorizer: TfidfVectorizer,\n",
    "    prereq_graph: Dict[str, List[str]],\n",
    "    postreq_graph: Dict[str, List[str]],\n",
    "    topk: int = 20,\n",
    "    mmr_lambda: float = 0.7,\n",
    "    tfidf_weight: float = 0.6,\n",
    "    rule_weight: float = 0.4\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # Extract profile parameters\n",
    "    interests = profile.get('interests', '')\n",
    "    completed = profile.get('courses_completed', [])\n",
    "    in_progress = profile.get('courses_in_progress', [])\n",
    "    prefer_foundational = profile.get('prefer_foundational', False)\n",
    "    prefer_advanced = profile.get('prefer_advanced', False)\n",
    "\n",
    "    # STEP 1: Rule-Based Filtering (prerequisites)\n",
    "    # =============================================\n",
    "    all_courses = df['code'].tolist()\n",
    "\n",
    "    # FIX 1: Exclude courses already completed or in-progress\n",
    "    already_taken = set(completed + in_progress)\n",
    "    candidate_courses = [c for c in all_courses if c not in already_taken]\n",
    "\n",
    "    print(f\"Total courses: {len(all_courses)}\")\n",
    "    print(f\"Already completed or in-progress: {len(already_taken)}\")\n",
    "    print(f\"Candidates after excluding taken courses: {len(candidate_courses)}\")\n",
    "\n",
    "    eligible_courses = get_eligible_courses_improved(\n",
    "        candidate_courses,\n",
    "        completed,\n",
    "        in_progress,\n",
    "        prereq_graph\n",
    "    )\n",
    "\n",
    "    # Detect student year for level-based boosting\n",
    "    student_year = detect_student_year(completed)\n",
    "    print(f\"Detected student year: {student_year}\")\n",
    "\n",
    "    # FIX 2: Hard filter for course levels based on student year\n",
    "    # Freshmen/Sophomores: No 400+ level courses\n",
    "    # Juniors: OK with 400-level, no 500-level\n",
    "    # Seniors: All levels OK\n",
    "    level_filtered = []\n",
    "    year_to_level = {\n",
    "        'freshman': 1,\n",
    "        'sophomore': 2,\n",
    "        'junior': 3,\n",
    "        'senior': 4\n",
    "    }\n",
    "    max_level_allowed = year_to_level.get(student_year, 2) + 1  # Can take 1 level above\n",
    "\n",
    "    for course in eligible_courses:\n",
    "        course_level = get_course_level(course)\n",
    "        if course_level <= max_level_allowed:\n",
    "            level_filtered.append(course)\n",
    "\n",
    "    print(f\"After level filtering (max level {max_level_allowed}): {len(level_filtered)} courses\")\n",
    "\n",
    "    # Filter dataframe to only eligible courses\n",
    "    df_eligible = df[df['code'].isin(level_filtered)].copy()\n",
    "    eligible_indices = df_eligible.index.tolist()\n",
    "\n",
    "    if len(df_eligible) == 0:\n",
    "        print(\"\\n⚠️ No eligible courses found!\")\n",
    "        print(\"  This might be because:\")\n",
    "        print(\"  - All appropriate-level courses require prerequisites you haven't met\")\n",
    "        print(\"  - You've already completed/are taking most available courses\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Final eligible courses: {len(df_eligible)}\")\n",
    "\n",
    "    # Get TF-IDF vectors for eligible courses\n",
    "    X_eligible = X_tfidf[eligible_indices]\n",
    "\n",
    "    # STEP 2: TF-IDF Interest Scoring\n",
    "    # =================================\n",
    "    # Use interests as-is (no typo fixing needed with real course descriptions)\n",
    "    print(f\"\\nUser interests: '{interests}'\")\n",
    "\n",
    "    # Vectorize user interests\n",
    "    query_vec = vectorizer.transform([interests])\n",
    "\n",
    "    # Calculate cosine similarity (0-1 range)\n",
    "    interest_scores = cosine_similarity(query_vec, X_eligible).flatten()\n",
    "\n",
    "    # STEP 3: Rule-Based Boosting\n",
    "    # ============================\n",
    "    rule_boosts = np.array([\n",
    "        calculate_rule_based_boost(\n",
    "            row,\n",
    "            student_year,\n",
    "            prefer_foundational,\n",
    "            prefer_advanced\n",
    "        )\n",
    "        for _, row in df_eligible.iterrows()\n",
    "    ])\n",
    "\n",
    "    # STEP 4: Combine Scores (Weighted Average + Boosting)\n",
    "    # =====================================================\n",
    "    # Method: Interest score (weighted) * rule boost\n",
    "    boosted_scores = interest_scores * rule_boosts\n",
    "\n",
    "    non_zero_mask = interest_scores > 0\n",
    "    if non_zero_mask.sum() > 0:\n",
    "        print(f\"  Courses with interest match: {non_zero_mask.sum()}\")\n",
    "\n",
    "        # Keep only non-zero interest courses\n",
    "        df_eligible = df_eligible[non_zero_mask].copy()\n",
    "        eligible_indices = [idx for idx, mask in zip(eligible_indices, non_zero_mask) if mask]\n",
    "        X_eligible = X_eligible[non_zero_mask]\n",
    "        interest_scores = interest_scores[non_zero_mask]\n",
    "        rule_boosts = rule_boosts[non_zero_mask]\n",
    "        boosted_scores = boosted_scores[non_zero_mask]\n",
    "\n",
    "    print(f\"\\nScore statistics:\")\n",
    "    print(f\"  Interest scores: mean={interest_scores.mean():.3f}, max={interest_scores.max():.3f}\")\n",
    "    print(f\"  Rule boosts: mean={rule_boosts.mean():.3f}, max={rule_boosts.max():.3f}\")\n",
    "    print(f\"  Final scores: mean={boosted_scores.mean():.3f}, max={boosted_scores.max():.3f}\")\n",
    "\n",
    "    # STEP 5: Apply MMR for Diversity\n",
    "    # ================================\n",
    "    top_indices = mmr_diversify(boosted_scores, X_eligible, min(topk, len(df_eligible)), mmr_lambda)\n",
    "\n",
    "    # Get results\n",
    "    result_df_indices = [eligible_indices[i] for i in top_indices]\n",
    "    result = df.loc[result_df_indices].copy()\n",
    "    result['interest_score'] = interest_scores[top_indices]\n",
    "    result['rule_boost'] = rule_boosts[top_indices]\n",
    "    result['final_score'] = boosted_scores[top_indices]\n",
    "    result = result.sort_values('final_score', ascending=False)\n",
    "\n",
    "    return result[[\n",
    "        'code', 'name', 'subject', 'level', 'prereq_count', 'postreq_count',\n",
    "        'interest_score', 'rule_boost', 'final_score'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f51563d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 2 course(s)\n",
      "In Progress: 3 courses\n",
      "Interests: genetics molecular biology cell signaling\n",
      "Preferences: advanced=False, foundational=True\n",
      "\n",
      "✓ Loaded Biochemistry, BS\n",
      "  Required courses: 27\n",
      "  Elective courses: 0\n",
      "  Area courses: 0\n",
      "\n",
      "✓ Loaded 43 courses for your major\n",
      "\n",
      "✓ Built recommendation model (952 features)\n",
      "Total courses: 43\n",
      "Already completed or in-progress: 5\n",
      "Candidates after excluding taken courses: 39\n",
      "Detected student year: first_year\n",
      "After level filtering (max level 3): 16 courses\n",
      "Final eligible courses: 16\n",
      "\n",
      "User interests: 'genetics molecular biology cell signaling'\n",
      "\n",
      "Filtering to courses with non-zero interest scores...\n",
      "  Courses with interest match: 6\n",
      "\n",
      "Score statistics:\n",
      "  Interest scores: mean=0.095, max=0.206\n",
      "  Rule boosts: mean=1.207, max=1.320\n",
      "  Final scores: mean=0.121, max=0.272\n",
      "\n",
      "================================================================================\n",
      "TOP 6 RECOMMENDED COURSES\n",
      "================================================================================\n",
      "\n",
      "MCB 250         | Level: intermediate    | Score: 0.272\n",
      "  Molecular Genetics\n",
      "  Interest Match: 0.206 | Curriculum Boost: 1.32x\n",
      "  Prerequisites: 3 | Unlocks: 16 courses\n",
      "\n",
      "MCB 250         | Level: intermediate    | Score: 0.272\n",
      "  Molecular Genetics\n",
      "  Interest Match: 0.206 | Curriculum Boost: 1.32x\n",
      "  Prerequisites: 3 | Unlocks: 16 courses\n",
      "\n",
      "MCB 150         | Level: introductory    | Score: 0.064\n",
      "  Molecular & Cellular Basis of Life\n",
      "  Interest Match: 0.053 | Curriculum Boost: 1.20x\n",
      "  Prerequisites: 0 | Unlocks: 14 courses\n",
      "\n",
      "MCB 150         | Level: introductory    | Score: 0.064\n",
      "  Molecular & Cellular Basis of Life\n",
      "  Interest Match: 0.053 | Curriculum Boost: 1.20x\n",
      "  Prerequisites: 0 | Unlocks: 14 courses\n",
      "\n",
      "STAT 212        | Level: intermediate    | Score: 0.028\n",
      "  Biostatistics\n",
      "  Interest Match: 0.025 | Curriculum Boost: 1.10x\n",
      "  Prerequisites: 0 | Unlocks: 2 courses\n",
      "\n",
      "STAT 212        | Level: intermediate    | Score: 0.028\n",
      "  Biostatistics\n",
      "  Interest Match: 0.025 | Curriculum Boost: 1.10x\n",
      "  Prerequisites: 0 | Unlocks: 2 courses\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>subject</th>\n",
       "      <th>level</th>\n",
       "      <th>prereq_count</th>\n",
       "      <th>postreq_count</th>\n",
       "      <th>interest_score</th>\n",
       "      <th>rule_boost</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MCB 250</td>\n",
       "      <td>Molecular Genetics</td>\n",
       "      <td>MCB</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.205722</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.271553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MCB 250</td>\n",
       "      <td>Molecular Genetics</td>\n",
       "      <td>MCB</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.205722</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.271553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MCB 150</td>\n",
       "      <td>Molecular &amp; Cellular Basis of Life</td>\n",
       "      <td>MCB</td>\n",
       "      <td>introductory</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.053384</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.064060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MCB 150</td>\n",
       "      <td>Molecular &amp; Cellular Basis of Life</td>\n",
       "      <td>MCB</td>\n",
       "      <td>introductory</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.053384</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.064060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>STAT 212</td>\n",
       "      <td>Biostatistics</td>\n",
       "      <td>STAT</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025414</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.027956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>STAT 212</td>\n",
       "      <td>Biostatistics</td>\n",
       "      <td>STAT</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025414</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.027956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code                                name subject         level  \\\n",
       "26   MCB 250                  Molecular Genetics     MCB  intermediate   \n",
       "32   MCB 250                  Molecular Genetics     MCB  intermediate   \n",
       "25   MCB 150  Molecular & Cellular Basis of Life     MCB  introductory   \n",
       "31   MCB 150  Molecular & Cellular Basis of Life     MCB  introductory   \n",
       "41  STAT 212                       Biostatistics    STAT  intermediate   \n",
       "42  STAT 212                       Biostatistics    STAT  intermediate   \n",
       "\n",
       "    prereq_count  postreq_count  interest_score  rule_boost  final_score  \n",
       "26             3             16        0.205722        1.32     0.271553  \n",
       "32             3             16        0.205722        1.32     0.271553  \n",
       "25             0             14        0.053384        1.20     0.064060  \n",
       "31             0             14        0.053384        1.20     0.064060  \n",
       "41             0              2        0.025414        1.10     0.027956  \n",
       "42             0              2        0.025414        1.10     0.027956  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "YOUR_MAJOR = \"Biochemistry, BS\"  \n",
    "\n",
    "YOUR_COMPLETED = ['CHEM 102', 'BIOL 110']  \n",
    "\n",
    "YOUR_IN_PROGRESS = [  \n",
    "    'CHEM 104', 'BIOL 120', 'MATH 220'\n",
    "]\n",
    "\n",
    "\n",
    "YOUR_INTERESTS = 'genetics molecular biology cell signaling'  \n",
    "\n",
    "\n",
    "PREFER_ADVANCED = False      # Set True if you want 400-level courses\n",
    "PREFER_FOUNDATIONAL = True   # Set True to prioritize courses that unlock more courses\n",
    "\n",
    "print(f\"Completed: {len(YOUR_COMPLETED)} course(s)\")\n",
    "print(f\"In Progress: {len(YOUR_IN_PROGRESS)} courses\")\n",
    "print(f\"Interests: {YOUR_INTERESTS}\")\n",
    "print(f\"Preferences: advanced={PREFER_ADVANCED}, foundational={PREFER_FOUNDATIONAL}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    major_data = load_major_requirements(MAJORS_FILE, YOUR_MAJOR)\n",
    "    tech_courses = extract_technical_courses(major_data)\n",
    "\n",
    "    print(f\"\\n✓ Loaded {YOUR_MAJOR}\")\n",
    "    print(f\"  Required courses: {len(tech_courses['required'])}\")\n",
    "    print(f\"  Elective courses: {len(tech_courses['electives'])}\")\n",
    "    print(f\"  Area courses: {len(tech_courses['areas'])}\")\n",
    "\n",
    "    # Create course dataframe\n",
    "    all_technical = tech_courses['required'] + tech_courses['electives'] + tech_courses['areas']\n",
    "    courses_df = create_technical_course_dataframe(all_technical, all_courses_df, prereq_graph, postreq_graph)\n",
    "\n",
    "    print(f\"\\n✓ Loaded {len(courses_df)} courses for your major\")\n",
    "\n",
    "    # Build TF-IDF for this major's courses\n",
    "    corpus = build_text_corpus(courses_df)\n",
    "    vectorizer = fit_vectorizer(corpus)\n",
    "    X_tfidf = vectorizer.transform(corpus)\n",
    "\n",
    "    print(f\"\\n✓ Built recommendation model ({X_tfidf.shape[1]} features)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error loading major: {e}\")\n",
    "    print(\"\\nAvailable majors (first 30):\")\n",
    "    majors = load_json(MAJORS_FILE)\n",
    "    for major_name in sorted(majors.keys())[:30]:\n",
    "        print(f\"  - {major_name}\")\n",
    "    raise\n",
    "\n",
    "# Create profile\n",
    "my_profile = {\n",
    "    'interests': YOUR_INTERESTS,\n",
    "    'courses_completed': YOUR_COMPLETED,\n",
    "    'courses_in_progress': YOUR_IN_PROGRESS,\n",
    "    'prefer_advanced': PREFER_ADVANCED,\n",
    "    'prefer_foundational': PREFER_FOUNDATIONAL\n",
    "}\n",
    "\n",
    "\n",
    "my_recommendations = recommend_technical_courses_hybrid(\n",
    "    my_profile,\n",
    "    YOUR_MAJOR,\n",
    "    courses_df,\n",
    "    X_tfidf,\n",
    "    vectorizer,\n",
    "    prereq_graph,\n",
    "    postreq_graph,\n",
    "    topk=20\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TOP {len(my_recommendations)} RECOMMENDED COURSES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not my_recommendations.empty:\n",
    "    for idx, row in my_recommendations.iterrows():\n",
    "        print(f\"\\n{row['code']:15} | Level: {row['level']:15} | Score: {row['final_score']:.3f}\")\n",
    "        print(f\"  {row['name']}\")\n",
    "        print(f\"  Interest Match: {row['interest_score']:.3f} | Curriculum Boost: {row['rule_boost']:.2f}x\")\n",
    "        print(f\"  Prerequisites: {row['prereq_count']} | Unlocks: {row['postreq_count']} courses\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(\"=\"*80)\n",
    "    display(my_recommendations)\n",
    "else:\n",
    "    print(\"\\n⚠️ No recommendations found. This might be because:\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
